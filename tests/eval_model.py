import json
from app import model, vectorstore  # reuse your loaded model and vectorstore
from langchain.chains import ConversationalRetrievalChain
from langchain.chains.conversation.memory import ConversationBufferMemory

EVAL_FILE = "tests/eval_queries.json"

def load_tests(path=EVAL_FILE):
    with open(path, "r") as f:
        return json.load(f)

def run_tests():
    tests = load_tests()
    passed = 0

    memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
    chain = ConversationalRetrievalChain.from_llm(
        llm=model,
        retriever=vectorstore.as_retriever(),
        memory=memory,
    )

    for test in tests:
        query = test["query"]
        expected_keywords = test["expected_keywords"]

        result = chain.run(query)
        print(f"\nğŸŸ¡ Query: {query}")
        print(f"ğŸ“¨ Response: {result}")

        if all(word.lower() in result.lower() for word in expected_keywords):
            print("âœ… PASSED")
            passed += 1
        else:
            print(f"âŒ FAILED. Missing keywords: {[w for w in expected_keywords if w.lower() not in result.lower()]}")

    print(f"\nğŸ {passed}/{len(tests)} tests passed.")

if __name__ == "__main__":
    run_tests()
