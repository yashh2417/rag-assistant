{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b54a254-4ad8-40fe-9688-c7111dc99718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "594c225f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d62e8db2-a565-4c0e-b7a4-a34bd8db52d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab5edd9f-f0aa-4577-83f9-65a02585a266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeef728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a32e6362-fb21-4d53-8542-aa88a0654195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "gemini_embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/embedding-001\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b869fad-2085-4782-8e39-3d5b22ced3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "model = ChatGoogleGenerativeAI(model = \"gemini-2.0-flash\", convert_system_message_to_human=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca6e1dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## setting PINECONE API KEY nad PINECONE ENVIRONMENT in the environment\n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"] = os.getenv(\"PINECONE_API_KEY\")\n",
    "os.environ[\"PINECONE_API_ENV\"] = \"us-east-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c7311ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "vectorstore = PineconeVectorStore(index_name=\"smart-assistant\", embedding=gemini_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a7dcd31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'who won ipl 2025?',\n",
       " 'result': 'Royal Challengers Bengaluru won the IPL in 2025.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain.chains import RetrievalQA  \n",
    "\n",
    "qa = RetrievalQA.from_chain_type(  \n",
    "    llm=model,  \n",
    "    chain_type=\"stuff\",  \n",
    "    retriever=vectorstore.as_retriever()  \n",
    ")  \n",
    "qa.invoke(\"who won ipl 2025?\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69eb6940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'who played champions trophhie semi finals?',\n",
       " 'result': 'The semi-final matches of the 2025 ICC Champions Trophy were:\\n\\n*   India (A1) vs Australia (B2)\\n*   New Zealand (A2) vs South Africa (B1)'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.invoke(\"who played champions trophhie semi finals?\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe53b3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'who won ipl 2025?',\n",
       " 'answer': 'Royal Challengers Bengaluru won IPL 2025.\\n',\n",
       " 'sources': '/Users/yash/Library/mcqgen/app/Assistant/pdf_docs/ipl2025.pdf'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain  \n",
    "qa_with_sources = RetrievalQAWithSourcesChain.from_chain_type(  \n",
    "    llm=model,  \n",
    "    chain_type=\"stuff\",  \n",
    "    retriever=vectorstore.as_retriever()  \n",
    ")  \n",
    "qa_with_sources.invoke(\"who won ipl 2025?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6c1901e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory=ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[]), return_messages=True, memory_key='chat_history') verbose=False combine_docs_chain=StuffDocumentsChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"Use the following pieces of context to answer the user's question. \\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\n{context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})]), llm=ChatGoogleGenerativeAI(model='models/gemini-2.0-flash', google_api_key=SecretStr('**********'), client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x10d4c78e0>, default_metadata=(), convert_system_message_to_human=True, model_kwargs={}), output_parser=StrOutputParser(), llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_variable_name='context') question_generator=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['chat_history', 'question'], input_types={}, partial_variables={}, template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:'), llm=ChatGoogleGenerativeAI(model='models/gemini-2.0-flash', google_api_key=SecretStr('**********'), client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x10d4c78e0>, default_metadata=(), convert_system_message_to_human=True, model_kwargs={}), output_parser=StrOutputParser(), llm_kwargs={}) retriever=VectorStoreRetriever(tags=['PineconeVectorStore', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_pinecone.vectorstores.PineconeVectorStore object at 0x10d5057e0>, search_kwargs={})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v3/hj2d2g150gld7k2cm6q9d9gh0000gn/T/ipykernel_68094/3842712392.py:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
    "\n",
    "# ðŸ§  Memory\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "# ConversationalRetrievalChain using .from_llm\n",
    "rag_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=model,\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "print(rag_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9f78c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sai Sudharsan of Gujarat Titans scored the most runs in IPL 2025 with 759 runs.\n"
     ]
    }
   ],
   "source": [
    "print(rag_chain.invoke(\"who scored most runs in ipl 2025?\")[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24fa1141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sai Sudharsan has won the following awards:\n",
      "\n",
      "*   Fantasy player of the season\n",
      "*   Orange Cap (most runs)\n",
      "*   Emerging player of the season\n",
      "*   Most fours\n"
     ]
    }
   ],
   "source": [
    "print(rag_chain.invoke(\"which award has he won?\")[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd93ceaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sai Sudharsan plays for Gujarat Titans.\n"
     ]
    }
   ],
   "source": [
    "print(rag_chain.invoke(\"for which team does he play?\")[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3d97081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shubman Gill is the captain of Gujarat Titans.\n"
     ]
    }
   ],
   "source": [
    "print(rag_chain.invoke(\"who is the caption of that team?\")[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa4240b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shubman Gill scored 90 runs in the match between Gujarat Titans and Kolkata Knight Riders, and 43 runs in the match between Mumbai Indians and Gujarat Titans.\n"
     ]
    }
   ],
   "source": [
    "print(rag_chain.invoke(\"how many runs did hw scored?\")[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc414ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
